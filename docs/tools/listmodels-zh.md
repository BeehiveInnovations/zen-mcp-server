# ListModels工具 - 列出可用模型

**按提供商显示所有可用AI模型**

`listmodels`工具显示哪些提供商已配置、可用模型、它们的别名、上下文窗口和能力。这对于理解可以使用哪些模型及其特性很有用。

## 用法

```
"使用zen列出可用模型"
```

## 关键功能

- **提供商组织**：显示所有已配置的提供商及其状态
- **模型能力**：上下文窗口、思考模式支持和特殊功能
- **别名映射**：显示简写名称及其完整模型映射
- **配置状态**：根据API密钥指示哪些提供商可用
- **上下文窗口信息**：帮助您根据内容大小需求选择模型
- **能力概述**：了解哪些模型支持扩展思考、视觉等

## 输出信息

工具显示：

**提供商状态：**
- 哪些提供商已配置且可用
- API密钥状态（不透露实际密钥）
- 提供商优先级顺序

**模型详细信息：**
- 完整模型名称及其别名
- 上下文窗口大小（tokens）
- 特殊能力（思考模式、视觉支持等）
- 提供商特定功能

**能力摘要：**
- 哪些模型支持扩展思考
- 支持图像分析的视觉模型
- 具有最大上下文窗口的模型
- 快速任务的最快模型

## 示例输出

```
📋 按提供商列出的可用模型

🔹 Google（Gemini） - ✅ 已配置
  • pro（gemini-2.5-pro） - 1M上下文，思考模式
  • flash（gemini-2.0-flash-experimental） - 1M上下文，超快

🔹 OpenAI - ✅ 已配置  
  • o3（o3） - 200K上下文，强推理
  • o3-mini（o3-mini） - 200K上下文，平衡
  • o4-mini（o4-mini） - 200K上下文，最新推理

🔹 自定义/本地 - ✅ 已配置
  • local-llama（llama3.2） - 128K上下文，本地推理
  • 可用于：http://localhost:11434/v1

🔹 OpenRouter - ❌ 未配置
  设置OPENROUTER_API_KEY以启用访问Claude、GPT-4和更多模型
```

## 何时使用ListModels

- **模型选择**：当您不确定哪些模型可用时
- **能力检查**：验证每个模型支持什么功能
- **配置验证**：确认您的API密钥正在工作
- **上下文规划**：根据内容大小要求选择模型
- **性能优化**：为速度与质量权衡选择合适的模型

## 配置依赖

可用模型取决于您的配置：

**所需API密钥：**
- `GEMINI_API_KEY` - 启用Gemini Pro和Flash模型
- `OPENAI_API_KEY` - 启用OpenAI O3、O4-mini和GPT模型
- `OPENROUTER_API_KEY` - 通过OpenRouter启用访问多个提供商
- `CUSTOM_API_URL` - 启用本地/自定义模型（Ollama、vLLM等）

**模型限制：**
如果您通过环境变量设置了模型使用限制，工具将显示：
- 哪些模型被允许与受限
- 活跃限制策略
- 如何修改限制

## 工具参数

此工具不需要参数 - 它只是查询服务器配置并显示所有可用信息。

## 最佳实践

- **规划前检查**：在开始复杂任务前使用此工具了解您的选项
- **验证配置**：确认您的API密钥按预期工作
- **选择适当模型**：将模型能力与您的特定需求匹配
- **了解限制**：处理大文件时注意上下文窗口

## 何时使用ListModels与其他工具

- **使用`listmodels`**：了解可用选项和模型能力
- **使用`chat`**：讨论为特定任务使用哪个模型
- **使用`version`**：服务器配置和版本信息
- **使用其他工具**：实际分析、调试或开发工作
