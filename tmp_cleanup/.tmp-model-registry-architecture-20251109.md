# Centralized Model Registry Architecture
**Date:** 2025-11-09
**Analysis:** Understanding the Data-Driven Model Management System

---

## Executive Summary

**CRITICAL DISCOVERY:** The project has a sophisticated centralized model registry system that I initially missed in my analysis.

### The Architecture (As Designed)

```
┌─────────────────────────────────────────────────────────────┐
│                  CENTRALIZED MODEL REGISTRY                  │
├─────────────────────────────────────────────────────────────┤
│                                                               │
│  models.csv (36 models)                                      │
│  ├── Model metadata (cost, performance, specialization)      │
│  ├── Benchmark scores (HumanEval, SWE-bench)                │
│  ├── Org level assignments (junior/senior/executive)         │
│  └── Role assignments (code_reviewer, architect, etc.)       │
│                                                               │
│  bands_config.json                                           │
│  ├── 9 band categories with centralized criteria             │
│  ├── Auto-classification rules                               │
│  ├── Cost tier definitions (free/economy/value/premium)      │
│  └── Performance bands (basic/good/excellent/exceptional)    │
│                                                               │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                    MODEL EVALUATION SYSTEM                   │
├─────────────────────────────────────────────────────────────┤
│                                                               │
│  model_evaluator Tool                                        │
│  ├── Input: OpenRouter URL for new model                    │
│  ├── Process: automated_evaluation_criteria.py               │
│  ├── Action: Add to models.csv if qualified                 │
│  └── Result: Automatic registry update                       │
│                                                               │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                      BAND SELECTOR ENGINE                    │
├─────────────────────────────────────────────────────────────┤
│                                                               │
│  BandSelector class (band_selector.py)                       │
│  ├── get_models_by_org_level(org_level, limit, role)        │
│  ├── get_models_by_cost_tier(tier, limit)                   │
│  ├── get_models_by_role(role, org_level, limit)             │
│  ├── get_models_by_specialization(spec, tier)               │
│  └── Data-driven: Queries models.csv using bands_config.json│
│                                                               │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                     CONSENSUS TOOLS (USERS)                  │
├─────────────────────────────────────────────────────────────┤
│                                                               │
│  Advanced Consensus Tools                                    │
│  ├── smart_consensus_v2                                      │
│  ├── layered_consensus                                       │
│  └── smart_consensus_advanced                                │
│                                                               │
│  How It SHOULD Work:                                         │
│  1. User specifies org_level (startup/scaleup/enterprise)    │
│  2. Tool specifies roles (code_reviewer, architect, etc.)    │
│  3. BandSelector returns appropriate models                  │
│  4. NO HARDCODED MODEL LISTS                                │
│  5. Automatically adapts when models.csv updates             │
│                                                               │
└─────────────────────────────────────────────────────────────┘
```

---

## Part 1: The Centralized Model Registry

### models.csv - Single Source of Truth

**Location:** `/home/byron/dev/zen-mcp-server/docs/models/models.csv`

**36 Models Across 6 Tiers:**

| Tier | Count | Cost Range | Performance | Example Models |
|------|-------|------------|-------------|----------------|
| **premium** | 5 | $5-75/M tokens | HumanEval 85-90 | gpt-5, claude-opus-4.1, gemini-2.5-pro |
| **high_perf** | 7 | $0.40-15/M tokens | HumanEval 75-85 | claude-sonnet-4, gpt-5-mini, deepseek-r1 |
| **value_tier** | 4 | $0.10-6/M tokens | HumanEval 70-78 | phi-4, mistral-large, kimi-k2 |
| **open_source** | 4 | $0.075-2/M tokens | HumanEval 75-85 | gemini-flash, o4-mini, qwen3-coder |
| **free_champion** | 6 | $0 | HumanEval 72-80.5 | llama-405b:free, qwen-coder:free |
| **free_tier** | 10 | $0 | HumanEval 58-72 | llama-3.3-70b:free, qwq-32b:free |

**Key Columns:**
```csv
rank,model,provider,tier,status,context,input_cost,output_cost,
org_level,specialization,role,strength,humaneval_score,swe_bench_score,
openrouter_url,last_updated
```

**Critical Insight:** Every model has pre-assigned:
- **org_level**: junior/senior/executive
- **role**: code_reviewer, senior_developer, lead_architect, etc.
- **specialization**: coding, reasoning, general, vision, debugging
- **tier**: Maps to cost tier (premium, high_perf, value_tier, free_champion, free_tier)

---

## Part 2: Band Configuration System

### bands_config.json - Centralized Criteria

**Location:** `/home/byron/dev/zen-mcp-server/docs/models/bands_config.json`

**9 Band Categories:**

#### 1. **org_level_assignment_bands**
```json
{
  "junior": {
    "cost_criteria": {"max_input_cost": 1.0},
    "performance_criteria": {"min_humaneval": 60.0},
    "context_criteria": {"min_context": 32000}
  },
  "senior": {
    "cost_criteria": {"max_input_cost": 10.0},
    "performance_criteria": {"min_humaneval": 70.0},
    "context_criteria": {"min_context": 65000}
  },
  "executive": {
    "cost_criteria": {"unlimited": true},
    "performance_criteria": {"min_humaneval": 80.0},
    "context_criteria": {"min_context": 128000}
  }
}
```

**Additive Structure:**
- Junior: cost ≤ $1, performance ≥ 60
- Senior: cost ≤ $10, performance ≥ 70 (INCLUDES some junior models)
- Executive: unlimited cost, performance ≥ 80 (INCLUDES some senior models)

#### 2. **cost_tier_bands**
```json
{
  "free": {"max_cost": 0.0},
  "economy": {"min_cost": 0.01, "max_cost": 1.0},
  "value": {"min_cost": 1.01, "max_cost": 10.0},
  "premium": {"min_cost": 10.01}
}
```

#### 3. **performance_bands**
```json
{
  "basic": {"max_score": 65.0},
  "good": {"min_score": 65.1, "max_score": 75.0},
  "excellent": {"min_score": 75.1, "max_score": 85.0},
  "exceptional": {"min_score": 85.1}
}
```

#### 4. **role_assignment_bands**
```json
{
  "technical_roles": {
    "criteria": {
      "specialization": ["coding", "debugging"],
      "min_humaneval": 70.0,
      "max_cost": 10.0
    },
    "roles": ["senior_developer", "code_reviewer", "qa_engineer"]
  },
  "architecture_roles": {
    "criteria": {
      "tier": ["premium", "high_perf"],
      "min_humaneval": 80.0,
      "min_context": 200000
    },
    "roles": ["lead_architect", "system_architect", "technical_director"]
  }
}
```

**Plus:** 5 more band categories (context_window, tier_classification, provider_trust, rank_assignment, strength_classification)

---

## Part 3: The BandSelector Engine

### How BandSelector Works

**File:** `/home/byron/dev/zen-mcp-server/tools/custom/band_selector.py`

**Core Methods:**

#### 1. `get_models_by_org_level(org_level, limit, role)`
```python
selector = BandSelector()

# Get startup tier models (junior band)
models = selector.get_models_by_org_level("startup", limit=3)
# Returns: Models with cost ≤ $1, humaneval ≥ 60

# Get scaleup tier models (senior band)
models = selector.get_models_by_org_level("scaleup", limit=6)
# Returns: Models with cost ≤ $10, humaneval ≥ 70

# Get enterprise tier models (executive band)
models = selector.get_models_by_org_level("enterprise", limit=8)
# Returns: Models with unlimited cost, humaneval ≥ 80
```

**Process:**
1. Maps org_level to band_key (startup→junior, scaleup→senior, enterprise→executive)
2. Gets criteria from `bands_config["org_level_assignment_bands"][band_key]`
3. Filters `models.csv` by criteria
4. Sorts by performance (HumanEval score)
5. Returns top N models

#### 2. `get_models_by_role(role, org_level, limit)`
```python
# Get models for specific role
models = selector.get_models_by_role("code_reviewer", "senior", limit=3)
# Returns: Models optimized for code review at senior level

# Architecture role
models = selector.get_models_by_role("lead_architect", "executive", limit=2)
# Returns: Premium models for architectural decisions
```

#### 3. `get_models_by_cost_tier(tier, limit)`
```python
# Get free models
models = selector.get_models_by_cost_tier("free", limit=5)
# Returns: Top 5 free models by performance

# Get premium models
models = selector.get_models_by_cost_tier("premium", limit=3)
# Returns: Top 3 premium models
```

---

## Part 4: Model Evaluation System

### Workflow for Adding New Models

**Example: Claude Sonnet 4.5 is released**

#### Step 1: User Runs model_evaluator Tool
```python
# Via MCP tool call
model_evaluator(
    openrouter_url="https://openrouter.ai/anthropic/claude-sonnet-4.5",
    evaluation_type="comprehensive"
)
```

#### Step 2: Automated Evaluation (automated_evaluation_criteria.py)
```python
class ModelEvaluator:
    def evaluate_model_for_replacement(self, openrouter_url):
        # 1. Extract model data from OpenRouter API
        model_data = self._extract_openrouter_data(url)

        # 2. Gather benchmarks (HumanEval, SWE-bench, MMLU, etc.)
        metrics = self._gather_model_metrics(model_data)

        # 3. Basic qualification check
        if not self._passes_basic_qualification(metrics):
            return {"qualified": False, "reason": "..."}

        # 4. Find replacement candidates
        candidates = self._find_replacement_candidates(metrics)

        # 5. Calculate replacement scores
        best_replacement = self._calculate_best_replacement(metrics, candidates)

        return {
            "qualified": True,
            "replacement_recommended": best_replacement["score"] >= 7.5,
            "target_model": best_replacement["target"],
            "implementation_plan": {...}
        }
```

**Evaluation Criteria:**
```python
@dataclass
class ModelMetrics:
    name: str
    provider: str
    humaneval_score: float
    swe_bench_score: float
    mmlu_score: float
    input_cost: float  # per million tokens
    output_cost: float
    context_window: int
    api_availability: float  # uptime %
    has_multimodal: bool
    has_vision: bool
    training_cutoff_date: str
```

#### Step 3: Add to models.csv

If qualified and recommended:
```csv
rank,model,provider,tier,status,context,input_cost,output_cost,org_level,specialization,role,strength,humaneval_score,swe_bench_score,openrouter_url,last_updated
4,anthropic/claude-sonnet-4.5,anthropic,high_perf,paid,200K,3.0,15.0,senior,reasoning,senior_developer,balanced,87.0,74.0,https://openrouter.ai/anthropic/claude-sonnet-4.5,2025-11-09
```

#### Step 4: Automatic Propagation

**NO CODE CHANGES NEEDED!**

- BandSelector automatically picks up new model
- Consensus tools automatically use it (via BandSelector)
- Old model (e.g., claude-sonnet-4) can be deprecated or re-tiered

---

## Part 5: Current Implementation Gap

### What's Wrong Right Now

#### ❌ Problem 1: smart_consensus_v2 Has Hardcoded Model Lists

**File:** `tools/custom/smart_consensus_v2.py` (lines 108-122)

```python
# HARDCODED - Should use BandSelector instead!
FREE_MODELS = [
    "deepseek/deepseek-chat:free",  # ← 404 error from OpenRouter
    "meta-llama/llama-3.3-70b-instruct:free",
    "qwen/qwen-2.5-coder-32b-instruct:free",
    "microsoft/phi-4-reasoning:free",
    "meta-llama/llama-3.1-405b-instruct:free",
]

PREMIUM_MODELS = [
    "anthropic/claude-opus-4.1",
    "openai/gpt-5",
    "google/gemini-2.5-pro",
    "deepseek/deepseek-r1-0528",
    "mistralai/mistral-large-2411",
]
```

**Problems:**
- ❌ Not using centralized registry
- ❌ Hardcoded lists get stale
- ❌ deepseek/deepseek-chat:free no longer available
- ❌ Misses new models (e.g., Sonnet 4.5)
- ❌ Requires code updates when models change

**Should Be:**
```python
# Use BandSelector instead
from tools.custom.band_selector import BandSelector

selector = BandSelector()

# Get free models dynamically
FREE_MODELS = selector.get_models_by_cost_tier("free", limit=5)

# Get premium models dynamically
PREMIUM_MODELS = selector.get_models_by_cost_tier("premium", limit=5)
```

#### ❌ Problem 2: layered_consensus Is SimpleTool (Wrong Pattern)

**File:** `tools/custom/layered_consensus.py`

```python
class LayeredConsensusTool(SimpleTool):  # ← WRONG: Should be WorkflowTool
    """Tool for multi-layered consensus analysis..."""

    async def prepare_prompt(self, request):
        # Creates role assignments
        role_assignments = self._create_layer_assignments(request)

        # Creates prompt asking ONE model to simulate multiple perspectives
        return prompt  # ← Only makes 1 LLM call
```

**Problems:**
- ❌ SimpleTool = single LLM call
- ❌ Simulates multi-model consensus (not genuine)
- ❌ Testing confirmed: "Called gemini-2.5-flash ONCE"

**Should Be:**
- WorkflowTool for true multi-model calls
- Use BandSelector to get models for each tier
- Implement additive layering

#### ❌ Problem 3: Not Implementing Additive Tiers

**Current Behavior:**
```python
# smart_consensus_v2 selects INDEPENDENTLY per org_level
if org_level == "startup":
    models = select_3_free_models()  # e.g., [A, B, C]
elif org_level == "scaleup":
    models = select_6_models()       # e.g., [D, E, F, G, H, I]  ← Different models!
elif org_level == "enterprise":
    models = select_8_models()       # e.g., [J, K, L, M, N, O, P, Q]  ← Different again!
```

**Intended Behavior (Additive):**
```python
# Tier 1 (startup/junior)
tier1_models = selector.get_models_by_org_level("startup", limit=3)
# Returns: [A, B, C] (3 free models)

# Tier 2 (scaleup/senior) = Tier 1 + additions
tier2_models = tier1_models + selector.get_additional_models("scaleup", exclude=tier1_models, limit=3)
# Returns: [A, B, C, D, E, F] (original 3 + 3 medium-cost models)

# Tier 3 (enterprise/executive) = Tier 2 + additions
tier3_models = tier2_models + selector.get_additional_models("enterprise", exclude=tier2_models, limit=2)
# Returns: [A, B, C, D, E, F, G, H] (original 6 + 2 premium models)
```

---

## Part 6: Proposed Solution

### Option D: Data-Driven Additive Consensus (NEW RECOMMENDATION)

**Leverage the centralized model registry architecture properly**

#### Step 1: Enhance BandSelector with Additive Methods

**File:** `tools/custom/band_selector.py`

```python
class BandSelector:
    """Enhanced with additive tier selection."""

    def get_additive_tier_models(self, tier: int) -> List[str]:
        """
        Get models for additive tier structure.

        Args:
            tier: 1 (startup), 2 (scaleup), or 3 (enterprise)

        Returns:
            List of models that INCLUDES all lower tiers
        """
        if tier == 1:
            # Tier 1: Free models only
            return self.get_models_by_cost_tier("free", limit=3)

        elif tier == 2:
            # Tier 2: INCLUDES Tier 1 + adds medium-cost
            tier1 = self.get_models_by_cost_tier("free", limit=3)
            tier2_additions = self.get_models_by_cost_tier("economy", limit=3)
            return tier1 + tier2_additions  # ADDITIVE

        elif tier == 3:
            # Tier 3: INCLUDES Tier 2 + adds premium
            tier1 = self.get_models_by_cost_tier("free", limit=3)
            tier2_additions = self.get_models_by_cost_tier("economy", limit=3)
            tier3_additions = self.get_models_by_cost_tier("premium", limit=2)
            return tier1 + tier2_additions + tier3_additions  # ADDITIVE

    def get_role_specific_additive_models(self, tier: int, roles: List[str]) -> Dict[str, str]:
        """
        Get additive tier models with role assignments.

        Returns:
            Dict mapping role → model
        """
        models = self.get_additive_tier_models(tier)

        # Assign models to roles (round-robin or role-optimized)
        role_assignments = {}
        for i, role in enumerate(roles):
            # Get role-optimized model if possible
            role_model = self.get_models_by_role(role, limit=1)[0] if self.get_models_by_role(role, limit=1) else models[i % len(models)]
            role_assignments[role] = role_model

        return role_assignments
```

#### Step 2: Update smart_consensus_v2 to Use BandSelector

**File:** `tools/custom/smart_consensus_v2.py`

```python
from tools.custom.band_selector import BandSelector

class SmartConsensusTool(WorkflowTool):
    """Enhanced with data-driven model selection."""

    def __init__(self):
        super().__init__()
        self.band_selector = BandSelector()  # Use centralized registry

    # REMOVE hardcoded FREE_MODELS and PREMIUM_MODELS

    async def _create_role_assignments(self, request):
        """Create role assignments using BandSelector."""
        org_level = request.org_level

        # Map org_level to tier
        tier_mapping = {"startup": 1, "scaleup": 2, "enterprise": 3}
        tier = tier_mapping[org_level]

        # Get roles for this tier
        roles = self._get_roles_for_tier(tier)

        # Get additive tier models with role assignments
        role_assignments = self.band_selector.get_role_specific_additive_models(
            tier=tier,
            roles=roles
        )

        return role_assignments

    def _get_roles_for_tier(self, tier: int) -> List[str]:
        """Get roles for tier (additive)."""
        if tier == 1:
            return ["code_reviewer", "security_checker", "technical_validator"]
        elif tier == 2:
            return [
                "code_reviewer", "security_checker", "technical_validator",  # Tier 1
                "senior_developer", "system_architect", "devops_engineer",  # Tier 2 additions
            ]
        elif tier == 3:
            return [
                "code_reviewer", "security_checker", "technical_validator",  # Tier 1
                "senior_developer", "system_architect", "devops_engineer",  # Tier 2
                "lead_architect", "technical_director",  # Tier 3 additions
            ]
```

#### Step 3: Convert layered_consensus to WorkflowTool

**File:** `tools/custom/layered_consensus.py`

```python
from tools.workflow.base import WorkflowTool  # Change base class
from tools.custom.band_selector import BandSelector

class LayeredConsensusTool(WorkflowTool):  # ← Changed from SimpleTool
    """True multi-model additive consensus."""

    def __init__(self):
        super().__init__()
        self.band_selector = BandSelector()

    async def execute_step(self, step_number: int, request: LayeredConsensusRequest):
        """Execute one model consultation per step."""
        # Map org_level to tier
        tier_mapping = {"startup": 1, "scaleup": 2, "enterprise": 3}
        tier = tier_mapping[request.org_level]

        # Get additive tier models
        models = self.band_selector.get_additive_tier_models(tier)
        roles = self._get_roles_for_tier(tier)

        # Consult model for this step
        if step_number <= len(models):
            model = models[step_number - 1]
            role = roles[step_number - 1]

            response = await self._consult_model(model, role, request.question)

            return {
                "step": step_number,
                "model": model,
                "role": role,
                "analysis": response,
                "tier": tier,
            }
        else:
            # Final synthesis step
            return await self._synthesize_consensus(request)
```

---

## Part 7: Benefits of Data-Driven Approach

### 1. **Automatic Model Updates**

**Scenario: Sonnet 4.5 Released**

**Old Way (Hardcoded):**
```python
# Developer must manually update smart_consensus_v2.py
PREMIUM_MODELS = [
    "anthropic/claude-opus-4.1",
    "anthropic/claude-sonnet-4.5",  # ← Manual addition
    "openai/gpt-5",
    ...
]
# Deploy new code
```

**New Way (Data-Driven):**
```bash
# 1. Run model_evaluator tool
model_evaluator(openrouter_url="https://openrouter.ai/anthropic/claude-sonnet-4.5")

# 2. Tool adds to models.csv
# 3. BandSelector automatically picks it up
# 4. Consensus tools automatically use it
# NO CODE CHANGES NEEDED!
```

### 2. **Automatic Model Deprecation**

**Scenario: deepseek-chat:free Returns 404**

**Old Way:**
```python
# Error occurs
# Developer traces error to FREE_MODELS list
# Updates code manually
FREE_MODELS = [
    # "deepseek/deepseek-chat:free",  # ← Comment out
    "meta-llama/llama-3.3-70b-instruct:free",
    ...
]
# Deploy fix
```

**New Way:**
```bash
# 1. Update models.csv (change status to "deprecated")
# 2. BandSelector filters out deprecated models
# 3. Consensus tools automatically skip it
# NO CODE CHANGES NEEDED!
```

### 3. **Cost Optimization**

**Scenario: New Free Model Outperforms Paid Model**

**models.csv update:**
```csv
# New model added
rank,model,provider,tier,status,context,input_cost,output_cost,org_level,specialization,role,strength,humaneval_score
5,meta-llama/llama-5-405b-instruct:free,meta,free_champion,free,200K,0.0,0.0,senior,general,senior_developer,flagship,88.0
```

**Automatic Effect:**
- BandSelector ranks by performance
- New free model ranks higher than some paid models
- Consensus tools automatically prefer it for senior tier
- **Cost savings** without code changes

### 4. **Domain-Specific Consensus Tools**

**Original Goal:** "If we ever wanted to have a consensus tool focused on something other than code review, we could duplicate the advanced consensus tool, and change the roles to what we needed"

**New Implementation:**

```python
# security_focused_consensus.py
class SecurityConsensusTool(WorkflowTool):
    """Security-focused consensus."""

    def _get_roles_for_tier(self, tier):
        if tier == 1:
            return ["security_checker", "vulnerability_scanner", "compliance_validator"]
        elif tier == 2:
            return [
                "security_checker", "vulnerability_scanner", "compliance_validator",  # Tier 1
                "penetration_tester", "security_architect", "threat_modeler",  # Tier 2
            ]
        elif tier == 3:
            return [
                # Tier 1 + 2 roles
                "security_chief", "risk_analyst",  # Tier 3
            ]

    # Inherits all BandSelector logic
    # Automatically gets appropriate models from registry
    # NO hardcoded model lists
```

---

## Part 8: Migration Plan

### Phase 1: Fix Model Availability (Week 1) - URGENT

**Action:** Update models.csv to mark unavailable models

```csv
# Change status for unavailable models
rank,model,...,status,...
24,deepseek/deepseek-chat:free,...,deprecated,...  # ← Change from "free" to "deprecated"
```

**OR remove from file entirely**

**Result:** BandSelector automatically skips deprecated models

### Phase 2: Enhance BandSelector (Week 2)

**Action:** Add additive tier methods to BandSelector

```python
# Add to tools/custom/band_selector.py
def get_additive_tier_models(self, tier: int) -> List[str]:
    """Get models with additive tier structure."""
    # Implementation shown above

def get_role_specific_additive_models(self, tier: int, roles: List[str]) -> Dict[str, str]:
    """Get additive models with role assignments."""
    # Implementation shown above
```

**Testing:**
```python
selector = BandSelector()

# Test tier 1
tier1 = selector.get_additive_tier_models(1)
assert len(tier1) == 3
assert all(model.endswith(":free") for model in tier1)

# Test tier 2 (includes tier 1)
tier2 = selector.get_additive_tier_models(2)
assert len(tier2) == 6
assert all(m in tier2 for m in tier1)  # Tier 1 models included

# Test tier 3 (includes tier 2)
tier3 = selector.get_additive_tier_models(3)
assert len(tier3) == 8
assert all(m in tier3 for m in tier2)  # Tier 2 models included
```

### Phase 3: Update smart_consensus_v2 (Week 3)

**Action:** Replace hardcoded model lists with BandSelector calls

**Changes:**
1. Remove `FREE_MODELS` and `PREMIUM_MODELS` constants
2. Add `self.band_selector = BandSelector()` in `__init__`
3. Update `_create_role_assignments` to use BandSelector
4. Update `_select_models_for_role` to query registry

**Testing:**
```bash
# Test with startup tier
python -c "
from tools.custom.smart_consensus_v2 import SmartConsensusTool
tool = SmartConsensusTool()
assignments = tool._create_role_assignments({'org_level': 'startup'})
print(f'Startup roles: {len(assignments)}')
print(f'Models: {assignments.values()}')
"

# Should output:
# Startup roles: 3
# Models: [free_model_1, free_model_2, free_model_3]
```

### Phase 4: Convert layered_consensus (Week 4)

**Action:** Convert from SimpleTool to WorkflowTool

**Changes:**
1. Change base class: `class LayeredConsensusTool(WorkflowTool)`
2. Implement `execute_step` for sequential model consultation
3. Use BandSelector for model selection
4. Implement additive tier logic

**Testing:**
```bash
# Test multi-model calls
python communication_simulator_test.py --tool layered_consensus --org_level scaleup

# Should show:
# Step 1: Calling model 1 (tier 1 model)
# Step 2: Calling model 2 (tier 1 model)
# Step 3: Calling model 3 (tier 1 model)
# Step 4: Calling model 4 (tier 2 model)
# Step 5: Calling model 5 (tier 2 model)
# Step 6: Calling model 6 (tier 2 model)
# Step 7: Synthesizing consensus
```

### Phase 5: Documentation & Cleanup (Week 5-6)

**Actions:**
1. Update tool documentation to reference centralized registry
2. Create user guide for model_evaluator tool
3. Document additive tier structure
4. Remove obsolete files (smart_consensus_simple, etc.)

---

## Part 9: Comparison with Previous Analysis

### What I Got Wrong Initially

**My Initial Analysis:**
- ❌ Thought layered_consensus was the primary implementation
- ❌ Missed the centralized model registry entirely
- ❌ Recommended creating new tools instead of fixing existing architecture
- ❌ Didn't understand the data-driven design intent

**What I Now Understand:**
- ✅ Centralized model registry (models.csv + bands_config.json)
- ✅ BandSelector as the query engine
- ✅ model_evaluator for automatic model additions
- ✅ Data-driven design means NO hardcoded model lists
- ✅ Additive layering should use BandSelector
- ✅ Domain-specific consensus tools easy to create

### Updated Recommendation

**Previous:** Create new tiered_consensus tool OR enhance smart_consensus_v2

**NEW:** Use existing architecture properly:
1. Fix BandSelector to support additive tiers
2. Update smart_consensus_v2 to use BandSelector (remove hardcoded lists)
3. Convert layered_consensus to WorkflowTool
4. Leverage centralized registry for all model selection

**Effort Comparison:**
- Previous recommendation: 6-8 weeks
- New recommendation: 4-5 weeks (simpler, uses existing infrastructure)

---

## Part 10: Success Criteria

### Week 1: Model Availability Fixed
- [ ] models.csv updated (deprecated unavailable models)
- [ ] smart_consensus_v2 works with startup tier
- [ ] No 404 errors from OpenRouter

### Week 2: BandSelector Enhanced
- [ ] `get_additive_tier_models()` implemented
- [ ] `get_role_specific_additive_models()` implemented
- [ ] Unit tests pass for additive tier logic
- [ ] Tier 2 includes Tier 1's exact models
- [ ] Tier 3 includes Tier 2's exact models

### Week 3: smart_consensus_v2 Data-Driven
- [ ] Hardcoded model lists removed
- [ ] Uses BandSelector for all model selection
- [ ] Automatic adaptation when models.csv changes
- [ ] Integration tests pass

### Week 4: layered_consensus Converted
- [ ] Changed to WorkflowTool base class
- [ ] Multi-model calling implemented
- [ ] Additive tier structure working
- [ ] Testing confirms N sequential LLM calls

### Week 5-6: Documentation Complete
- [ ] User guide for model_evaluator tool
- [ ] Developer guide for BandSelector
- [ ] Additive tier structure documented
- [ ] Migration complete

---

## Conclusion

**The centralized model registry architecture is excellent - it just needs to be fully utilized.**

**Key Changes Needed:**
1. ✅ models.csv already exists (36 models)
2. ✅ bands_config.json already exists (9 band categories)
3. ✅ BandSelector already exists (query engine)
4. ✅ model_evaluator already exists (for adding models)
5. ❌ Consensus tools need to USE BandSelector (currently have hardcoded lists)
6. ❌ BandSelector needs additive tier support
7. ❌ layered_consensus needs WorkflowTool conversion

**Estimated Effort:** 4-5 weeks (vs 6-8 weeks for previous plan)

**Risk Level:** LOW (leverages existing architecture, no new systems needed)

**Maintainability Improvement:** HUGE (data-driven, automatic model updates, no code changes when models change)

---

**Next Step:** User confirms this approach aligns with original architecture vision
