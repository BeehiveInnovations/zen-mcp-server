{
  "_README": {
    "description": "Portkey AI Gateway model configuration with routing capabilities",
    "provider": "Portkey - Enterprise AI Gateway with observability and routing",
    "documentation": "https://portkey.ai/docs",
    "usage": "Models can be accessed via aliases (e.g., 'gpt4', 'claude', 'gemini') or full names",
    "instructions": [
      "Add new models by copying an existing entry and modifying it",
      "Aliases are case-insensitive and should be unique across all models",
      "context_window is the model's total context window size in tokens (input + output)",
      "Set supports_* flags based on the underlying model's capabilities",
      "provider_route field explicitly maps models to Portkey configs (recommended for reliability)",
      "Models route through Portkey's gateway based on your virtual key configuration",
      "Virtual keys determine which underlying AI provider is used (OpenAI, Anthropic, etc.)"
    ],
    "authentication": {
      "required_env_vars": ["PORTKEY_API_KEY", "PORTKEY_VIRTUAL_KEY"],
      "note": "Virtual key routes requests to specific AI providers through Portkey's gateway"
    }
  },
  "models": [
    {
      "model_name": "gpt-4",
      "aliases": ["gpt4", "openai"],
      "provider_route": "openai",
      "context_window": 128000,
      "max_output_tokens": 4096,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_images": true,
      "max_image_size_mb": 20.0,
      "supports_json_mode": true,
      "temperature_constraint": "range",
      "description": "GPT-4 via Portkey Gateway - Advanced reasoning and multimodal capabilities"
    },
    {
      "model_name": "gpt-3.5-turbo",
      "aliases": ["gpt35", "turbo"],
      "provider_route": "openai",
      "context_window": 16385,
      "max_output_tokens": 4096,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_images": false,
      "max_image_size_mb": 0.0,
      "supports_json_mode": true,
      "temperature_constraint": "range",
      "description": "GPT-3.5 Turbo via Portkey Gateway - Fast and cost-effective"
    },
    {
      "model_name": "claude-3-5-sonnet-20241022",
      "aliases": ["claude", "sonnet", "anthropic"],
      "provider_route": "anthropic",
      "context_window": 200000,
      "max_output_tokens": 8192,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_images": true,
      "max_image_size_mb": 20.0,
      "supports_json_mode": false,
      "temperature_constraint": "range",
      "description": "Claude 3.5 Sonnet via Portkey Gateway - Superior reasoning and analysis"
    },
    {
      "model_name": "claude-3-haiku-20240307",
      "aliases": ["haiku", "claude-fast"],
      "provider_route": "anthropic",
      "context_window": 200000,
      "max_output_tokens": 4096,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_images": true,
      "max_image_size_mb": 20.0,
      "supports_json_mode": false,
      "temperature_constraint": "range",
      "description": "Claude 3 Haiku via Portkey Gateway - Fast and efficient"
    },
    {
      "model_name": "gemini-1.5-pro",
      "aliases": ["gemini", "google"],
      "provider_route": "google",
      "context_window": 2097152,
      "max_output_tokens": 8192,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_images": true,
      "max_image_size_mb": 20.0,
      "supports_json_mode": true,
      "temperature_constraint": "range",
      "description": "Gemini 1.5 Pro via Portkey Gateway - Massive context window and multimodal"
    },
    {
      "model_name": "gemini-1.5-flash",
      "aliases": ["flash", "gemini-fast"],
      "provider_route": "google",
      "context_window": 1048576,
      "max_output_tokens": 8192,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_images": true,
      "max_image_size_mb": 20.0,
      "supports_json_mode": true,
      "temperature_constraint": "range",
      "description": "Gemini 1.5 Flash via Portkey Gateway - Fast inference with large context"
    },
    {
      "model_name": "o1-preview",
      "aliases": ["o1", "openai-reasoning"],
      "context_window": 128000,
      "max_output_tokens": 32768,
      "supports_extended_thinking": false,
      "supports_system_prompts": false,
      "supports_streaming": false,
      "supports_function_calling": false,
      "supports_images": true,
      "max_image_size_mb": 20.0,
      "supports_json_mode": false,
      "temperature_constraint": "fixed",
      "description": "OpenAI o1-preview via Portkey Gateway - Advanced reasoning model"
    },
    {
      "model_name": "llama-3.1-405b-instruct",
      "aliases": ["llama", "meta"],
      "context_window": 131072,
      "max_output_tokens": 4096,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_images": false,
      "max_image_size_mb": 0.0,
      "supports_json_mode": false,
      "temperature_constraint": "range",
      "description": "Llama 3.1 405B via Portkey Gateway - Large open-source model"
    },
    {
      "model_name": "mistral-large-2407",
      "aliases": ["mistral", "mistral-large"],
      "context_window": 128000,
      "max_output_tokens": 4096,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_images": false,
      "max_image_size_mb": 0.0,
      "supports_json_mode": true,
      "temperature_constraint": "range",
      "description": "Mistral Large via Portkey Gateway - European AI model"
    },
    {
      "model_name": "claude-sonnet-4",
      "aliases": ["sonnet4", "claude4"],
      "context_window": 200000,
      "max_output_tokens": 8192,
      "supports_extended_thinking": true,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_images": true,
      "max_image_size_mb": 20.0,
      "supports_json_mode": false,
      "temperature_constraint": "range",
      "description": "Claude Sonnet 4 via Portkey Gateway - Latest generation Claude model"
    }
  ]
}