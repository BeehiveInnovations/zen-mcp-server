{
  "_README": {
    "description": "Portkey AI Gateway model configuration with routing capabilities",
    "provider": "Portkey - Enterprise AI Gateway with observability and routing",
    "documentation": "https://portkey.ai/docs",
    "usage": "Models can be accessed via aliases (e.g., 'gpt4', 'claude', 'gemini') or full names",
    "instructions": [
      "Add new models by copying an existing entry and modifying it",
      "Aliases are case-insensitive and should be unique across all models",
      "context_window is the model's total context window size in tokens (input + output)",
      "Set supports_* flags based on the underlying model's capabilities",
      "Models route through Portkey's gateway based on your virtual key configuration",
      "Virtual keys determine which underlying AI provider is used (OpenAI, Anthropic, etc.)"
    ],
    "authentication": {
      "required_env_vars": ["PORTKEY_API_KEY", "PORTKEY_VIRTUAL_KEY"],
      "note": "Virtual key routes requests to specific AI providers through Portkey's gateway"
    }
  },
  "models": [
    {
      "model_name": "gpt-4",
      "aliases": ["gpt4", "openai"],
      "context_window": 128000,
      "max_output_tokens": 4096,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_images": true,
      "max_image_size_mb": 20.0,
      "supports_json_mode": true,
      "temperature_constraint": "range",
      "description": "GPT-4 via Portkey Gateway - Advanced reasoning and multimodal capabilities"
    },
    {
      "model_name": "gpt-3.5-turbo",
      "aliases": ["gpt35", "turbo"],
      "context_window": 16385,
      "max_output_tokens": 4096,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_images": false,
      "max_image_size_mb": 0.0,
      "supports_json_mode": true,
      "temperature_constraint": "range",
      "description": "GPT-3.5 Turbo via Portkey Gateway - Fast and cost-effective"
    },
    {
      "model_name": "claude-3-5-sonnet-20241022",
      "aliases": ["claude", "sonnet", "anthropic"],
      "context_window": 200000,
      "max_output_tokens": 8192,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_images": true,
      "max_image_size_mb": 20.0,
      "supports_json_mode": false,
      "temperature_constraint": "range",
      "description": "Claude 3.5 Sonnet via Portkey Gateway - Superior reasoning and analysis"
    },
    {
      "model_name": "claude-3-haiku-20240307",
      "aliases": ["haiku", "claude-fast"],
      "context_window": 200000,
      "max_output_tokens": 4096,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_images": true,
      "max_image_size_mb": 20.0,
      "supports_json_mode": false,
      "temperature_constraint": "range",
      "description": "Claude 3 Haiku via Portkey Gateway - Fast and efficient"
    },
    {
      "model_name": "gemini-1.5-pro",
      "aliases": ["gemini", "google"],
      "context_window": 2097152,
      "max_output_tokens": 8192,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_images": true,
      "max_image_size_mb": 20.0,
      "supports_json_mode": true,
      "temperature_constraint": "range",
      "description": "Gemini 1.5 Pro via Portkey Gateway - Massive context window and multimodal"
    },
    {
      "model_name": "gemini-1.5-flash",
      "aliases": ["flash", "gemini-fast"],
      "context_window": 1048576,
      "max_output_tokens": 8192,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_images": true,
      "max_image_size_mb": 20.0,
      "supports_json_mode": true,
      "temperature_constraint": "range",
      "description": "Gemini 1.5 Flash via Portkey Gateway - Fast inference with large context"
    },
    {
      "model_name": "o1-preview",
      "aliases": ["o1", "openai-reasoning"],
      "context_window": 128000,
      "max_output_tokens": 32768,
      "supports_extended_thinking": false,
      "supports_system_prompts": false,
      "supports_streaming": false,
      "supports_function_calling": false,
      "supports_images": true,
      "max_image_size_mb": 20.0,
      "supports_json_mode": false,
      "temperature_constraint": "fixed",
      "description": "OpenAI o1-preview via Portkey Gateway - Advanced reasoning model"
    },
    {
      "model_name": "llama-3.1-405b-instruct",
      "aliases": ["llama", "meta"],
      "context_window": 131072,
      "max_output_tokens": 4096,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_images": false,
      "max_image_size_mb": 0.0,
      "supports_json_mode": false,
      "temperature_constraint": "range",
      "description": "Llama 3.1 405B via Portkey Gateway - Large open-source model"
    },
    {
      "model_name": "mistral-large-2407",
      "aliases": ["mistral", "mistral-large"],
      "context_window": 128000,
      "max_output_tokens": 4096,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_images": false,
      "max_image_size_mb": 0.0,
      "supports_json_mode": true,
      "temperature_constraint": "range",
      "description": "Mistral Large via Portkey Gateway - European AI model"
    }
  ]
}